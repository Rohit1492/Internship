{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect to webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\roshan.LAPTOP-IHN8RLL4\\Downloads\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "#find element for job search bar. Searching job position by 'ID' and location by 'xpath'\n",
    "\n",
    "search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job.send_keys('Data Analyst')\n",
    "search_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys('Bangalore')\n",
    "\n",
    "#to click on search button\n",
    "search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Senior Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>Tech Data Advanced Solutions India Pvt Ltd</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst - Flipkart Analytics</td>\n",
       "      <td>Bangalore/Bengaluru(Bellandur)</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Business Data Analyst - Database Design/Mining</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Urgent Openings For Data Analyst / Business An...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Rupeek Fintech Pvt Ltd</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Business Data Analyst(BigId) - Capco - Bangalore</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Capco Technologies Pvt Ltd</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ShieldSquare _x001A_</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Kochi/Cochin, Cannanore/Kannur, Nagpur, Calicu...</td>\n",
       "      <td>CINDREBAY SCHOOL OF FASHION &amp; INTERIOR DESIGN</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Titan Consultancy</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Pioneer Business Solutions</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                       Senior Business Data Analyst   \n",
       "1                  Data Analyst - Flipkart Analytics   \n",
       "2     Business Data Analyst - Database Design/Mining   \n",
       "3  Urgent Openings For Data Analyst / Business An...   \n",
       "4                                       Data Analyst   \n",
       "5   Business Data Analyst(BigId) - Capco - Bangalore   \n",
       "6                                Senior Data Analyst   \n",
       "7                                       Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9                                Senior Data Analyst   \n",
       "\n",
       "                                            Location  \\\n",
       "0            Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "1                     Bangalore/Bengaluru(Bellandur)   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Kochi/Cochin, Cannanore/Kannur, Nagpur, Calicu...   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                         Company Experience  \n",
       "0     Tech Data Advanced Solutions India Pvt Ltd    3-8 Yrs  \n",
       "1                                       Flipkart    0-3 Yrs  \n",
       "2                                    AugmatrixGo    2-5 Yrs  \n",
       "3                                       Flipkart    1-6 Yrs  \n",
       "4                         Rupeek Fintech Pvt Ltd    0-2 Yrs  \n",
       "5                     Capco Technologies Pvt Ltd    3-8 Yrs  \n",
       "6                           ShieldSquare _x001A_   5-10 Yrs  \n",
       "7  CINDREBAY SCHOOL OF FASHION & INTERIOR DESIGN    1-4 Yrs  \n",
       "8                              Titan Consultancy    2-5 Yrs  \n",
       "9                     Pioneer Business Solutions   6-11 Yrs  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now extract all the tags having the job_title\n",
    "job_title =[]\n",
    "title_tags= driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tags\n",
    "\n",
    "#Extract title text from above scraped title_tags with the help of for loop\n",
    "for i in title_tags[:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "  \n",
    "    \n",
    "# extract all the tags having the job_location\n",
    "job_location =[]\n",
    "location_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "\n",
    "#Extract location text from above scraped location_tags with the help of for loop\n",
    "for i in location_tags[:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "\n",
    "# extract all the tags having the comoany_name\n",
    "company_name =[]\n",
    "company_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "#Extract company name text from above scraped company_tags with the help of for loop\n",
    "for i in company_tags[:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "                        \n",
    "# extract all the tags having the experience_required\n",
    "experience_required =[]\n",
    "exp_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "\n",
    "#Extract experience text from above scraped company_tags with the help of for loop\n",
    "for i in exp_tags[:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "\n",
    "#making data frame from above extraxted data\n",
    "df=pd.DataFrame({'Job_title': job_title,'Location':job_location,'Company':company_name,'Experience':experience_required})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect to webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\roshan.LAPTOP-IHN8RLL4\\Downloads\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "#find element for job search bar. Searching job position by 'ID' and location by 'xpath'\n",
    "\n",
    "search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job.send_keys('Data Scientist')\n",
    "search_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys('Bangalore')\n",
    "\n",
    "#to click on search button\n",
    "search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Senior Data Scientist- Data &amp; Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ExecBoardinAsia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Forecasting Analyst/ Data Scientist (US Client)</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Concentrix Daksh Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, M...</td>\n",
       "      <td>Toppr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Process Innovation Analyst - APAC/Data Scienti...</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad</td>\n",
       "      <td>Bayer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru(HSR Layout)</td>\n",
       "      <td>Mobiotics IT Solution Pvt Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                              Senior Data Scientist   \n",
       "1                 Data Scientist: Advanced Analytics   \n",
       "2                              Senior Data Scientist   \n",
       "3            Senior Data Scientist- Data & Analytics   \n",
       "4    Forecasting Analyst/ Data Scientist (US Client)   \n",
       "5                                     Data Scientist   \n",
       "6  Process Innovation Analyst - APAC/Data Scienti...   \n",
       "7                                     Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "5  Hyderabad/Secunderabad, Bangalore/Bengaluru, M...   \n",
       "6                     Bangalore/Bengaluru, Hyderabad   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                    Bangalore/Bengaluru(HSR Layout)   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                         Company  \n",
       "0         IBM India Pvt. Limited  \n",
       "1         IBM India Pvt. Limited  \n",
       "2                   Hitachi Ltd.  \n",
       "3                ExecBoardinAsia  \n",
       "4      Concentrix Daksh Services  \n",
       "5                          Toppr  \n",
       "6                          Bayer  \n",
       "7                   Hitachi Ltd.  \n",
       "8  Mobiotics IT Solution Pvt Ltd  \n",
       "9                   Hitachi Ltd.  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now extract all the tags having the job_title\n",
    "job_title1 =[]\n",
    "title_tags1= driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tags1\n",
    "\n",
    "#Extract title text from above scraped title_tags with the help of for loop\n",
    "for i in title_tags1[:10]:\n",
    "    title1=i.text\n",
    "    job_title1.append(title1)\n",
    "  \n",
    "    \n",
    "# extract all the tags having the job_location\n",
    "job_location1 =[]\n",
    "location_tags1 = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "\n",
    "#Extract location text from above scraped location_tags with the help of for loop\n",
    "for i in location_tags1[:10]:\n",
    "    location1=i.text\n",
    "    job_location1.append(location1)\n",
    "\n",
    "\n",
    "# extract all the tags having the comoany_name\n",
    "company_name1 =[]\n",
    "company_tags1 = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "#Extract company name text from above scraped company_tags with the help of for loop\n",
    "for i in company_tags1[:10]:\n",
    "    company1=i.text\n",
    "    company_name1.append(company1)\n",
    "    \n",
    "                    \n",
    "\n",
    "#making data frame from above extraxted data\n",
    "ds=pd.DataFrame({'Job_title': job_title1,'Location':job_location1,'Company':company_name1})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect to webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\roshan.LAPTOP-IHN8RLL4\\Downloads\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "#find element for job search bar. Searching job position by 'ID' and location by 'xpath'\n",
    "\n",
    "search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job.send_keys('Data Scientist')\n",
    "search_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys('Delhi/NCR')\n",
    "\n",
    "#to click on search button\n",
    "search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting salary range 3-6 lakhs\n",
    "search_sal=driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\")\n",
    "search_sal.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Forecasting Analyst/ Data Scientist (US Client)</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Concentrix Daksh Services</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist/ Analyst Specialist</td>\n",
       "      <td>Noida, New Delhi, Gurgaon/Gurugram, Delhi / NC...</td>\n",
       "      <td>TransOrg Solutions Services (P) Ltd.</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>TransOrg Solutions Services (P) Ltd.</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Conservation Data Scientist</td>\n",
       "      <td>Dehradun, New Delhi</td>\n",
       "      <td>World Wide Fund For Nature India</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Data Scientist - Insurance</td>\n",
       "      <td>Noida, Gurgaon/Gurugram</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Manager - Data Scientist/Python</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Noida(Sector-126 Noida)</td>\n",
       "      <td>AUDAX LABS PRIVATE LIMITED</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Editorialist YX</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>SPOTALENT</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Job_title  \\\n",
       "0  Forecasting Analyst/ Data Scientist (US Client)   \n",
       "1               Data Scientist/ Analyst Specialist   \n",
       "2                              Lead Data Scientist   \n",
       "3                      Conservation Data Scientist   \n",
       "4               Data Scientist: Advanced Analytics   \n",
       "5                       Data Scientist - Insurance   \n",
       "6                  Manager - Data Scientist/Python   \n",
       "7                            Senior Data Scientist   \n",
       "8                                   Data Scientist   \n",
       "9                            Senior Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "1  Noida, New Delhi, Gurgaon/Gurugram, Delhi / NC...   \n",
       "2  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "3                                Dehradun, New Delhi   \n",
       "4                                        Delhi / NCR   \n",
       "5                            Noida, Gurgaon/Gurugram   \n",
       "6                                   Gurgaon/Gurugram   \n",
       "7                            Noida(Sector-126 Noida)   \n",
       "8                                   Gurgaon/Gurugram   \n",
       "9  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...   \n",
       "\n",
       "                                Company Experience  \n",
       "0             Concentrix Daksh Services    3-8 Yrs  \n",
       "1  TransOrg Solutions Services (P) Ltd.    1-4 Yrs  \n",
       "2  TransOrg Solutions Services (P) Ltd.    4-9 Yrs  \n",
       "3      World Wide Fund For Nature India   5-10 Yrs  \n",
       "4                IBM India Pvt. Limited    2-7 Yrs  \n",
       "5             Huquo Consulting Pvt. Ltd    5-8 Yrs  \n",
       "6             Huquo Consulting Pvt. Ltd   7-10 Yrs  \n",
       "7            AUDAX LABS PRIVATE LIMITED    0-2 Yrs  \n",
       "8                       Editorialist YX    5-9 Yrs  \n",
       "9                             SPOTALENT    3-6 Yrs  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now extract all the tags having the job_title\n",
    "ds_title =[]\n",
    "ds_tags= driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "#Extract title text from above scraped title_tags with the help of for loop\n",
    "for i in ds_tags[:10]:\n",
    "    d_title=i.text\n",
    "    ds_title.append(d_title)\n",
    "ds_title \n",
    "    \n",
    "# extract all the tags having the job_location\n",
    "ds_location =[]\n",
    "loc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "\n",
    "#Extract location text from above scraped location_tags with the help of for loop\n",
    "for i in loc_tags[:10]:\n",
    "    loc=i.text\n",
    "    ds_location.append(loc)\n",
    "ds_location\n",
    "\n",
    "# extract all the tags having the comoany_name\n",
    "ds_company =[]\n",
    "comp_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "#Extract company name text from above scraped company_tags with the help of for loop\n",
    "for i in comp_tags[:10]:\n",
    "    comp=i.text\n",
    "    ds_company.append(comp)\n",
    "ds_company  \n",
    "                        \n",
    "# extract all the tags having the experience_required\n",
    "ds_experience_required =[]\n",
    "ds_exp_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "\n",
    "#Extract experience text from above scraped company_tags with the help of for loop\n",
    "for i in ds_exp_tags[:10]:\n",
    "    ds_exp=i.text\n",
    "    ds_experience_required.append(ds_exp)\n",
    "ds_experience_required\n",
    "\n",
    "#making data frame from above extraxted data\n",
    "df=pd.DataFrame({'Job_title': ds_title,'Location':ds_location,'Company':ds_company,'Experience':ds_experience_required})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect to webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\roshan.LAPTOP-IHN8RLL4\\Downloads\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n",
    "try:\n",
    "    search_btn=driver.find_element_by_xpath(\"//button[@class= '_2KpZ6l _2doB4z']\")\n",
    "    search_btn.click()\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "#To click on search button\n",
    "search_field = driver.find_element_by_name('q')\n",
    "search_field.send_keys('sunglasses')\n",
    "search_bt = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_bt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now extract all the tags having the Brand name\n",
    "Brand=[]\n",
    "tags1=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "\n",
    "#Extract brand text from above scraped tags with the help of for loop\n",
    "for i in tags1:\n",
    "    brand=i.text\n",
    "    Brand.append(brand)\n",
    "    \n",
    "# extract all the tags having the Product_Description\n",
    "Product_Description =[]\n",
    "prod_des = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "\n",
    "#Extract Product_Description text from above scraped tags with the help of for loop\n",
    "for i in prod_des:\n",
    "    product_des=i.text\n",
    "    Product_Description.append(product_des)\n",
    "\n",
    "# extract all the tags having the Price\n",
    "Price =[]\n",
    "pr = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "\n",
    "#Extract price text from above scraped tags with the help of for loop\n",
    "for i in pr:\n",
    "    price=i.text\n",
    "    Price.append(price)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page2\n"
     ]
    }
   ],
   "source": [
    "# Now clicking on next page-2\n",
    "print(\"page2\")\n",
    "page2 = driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "page2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting brand from next page\n",
    "\n",
    "tags2=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "for i in tags2:\n",
    "    b1=i.text\n",
    "    Brand.append(b1)\n",
    "    \n",
    "# extracting product_description from next page\n",
    "\n",
    "prod_des1 = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "for i in prod_des1:\n",
    "    p_des1=i.text\n",
    "    Product_Description.append(p_des1)\n",
    "    \n",
    "# extracting price from next page\n",
    "\n",
    "pr1 = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "for i in pr1:\n",
    "    price1=i.text\n",
    "    Price.append(price1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page3\n"
     ]
    }
   ],
   "source": [
    "# Now clicking on next page-3\n",
    "print(\"page3\")\n",
    "page2 = driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\")\n",
    "page2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Wayfarer Sunglasses (57)</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Wayfarer ...</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Round Sungl...</td>\n",
       "      <td>₹276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (55)</td>\n",
       "      <td>₹421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection, Others Round, Aviator Sunglasse...</td>\n",
       "      <td>₹189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>Fravy</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Rectangul...</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product_Description Price\n",
       "0    VINCENT CHASE  Polarized, UV Protection Wayfarer Sunglasses (57)  ₹799\n",
       "1    VINCENT CHASE  by Lenskart Polarized, UV Protection Wayfarer ...  ₹999\n",
       "2             SRPM             UV Protection Wayfarer Sunglasses (56)  ₹188\n",
       "3           SUNBEE  UV Protection, Polarized, Mirrored Round Sungl...  ₹276\n",
       "4         Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹639\n",
       "..             ...                                                ...   ...\n",
       "95          AISLIN             UV Protection Wayfarer Sunglasses (55)  ₹421\n",
       "96       ROYAL SON   UV Protection Rectangular Sunglasses (Free Size)  ₹449\n",
       "97  kingsunglasses  UV Protection, Others Round, Aviator Sunglasse...  ₹189\n",
       "98           Fravy  UV Protection Retro Square Sunglasses (Free Size)  ₹269\n",
       "99   VINCENT CHASE  by Lenskart Polarized, UV Protection Rectangul...  ₹799\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting brand from next page\n",
    "\n",
    "tags3=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "for i in tags3[0:20]:\n",
    "    b2=i.text\n",
    "    Brand.append(b2)\n",
    "    \n",
    "# extracting product_description from next page\n",
    "\n",
    "prod_des2 = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "for i in prod_des2[0:20]:\n",
    "    p_des2=i.text\n",
    "    Product_Description.append(p_des2)\n",
    "    \n",
    "# extracting price from next page\n",
    "\n",
    "pr2 = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "for i in pr2[0:20]:\n",
    "    price2=i.text\n",
    "    Price.append(price2)\n",
    "\n",
    "#making data frame from above extraxted data\n",
    "ds=pd.DataFrame({'Brand': Brand,'Product_Description':Product_Description,'Price':Price})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect to webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\roshan.LAPTOP-IHN8RLL4\\Downloads\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to the webpage server to get the source code of the page\n",
    "driver.get('s://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC \n",
    "TSVZAXUHGREPBFGI&marketplace')\n",
    "\n",
    "#Above link is not available so unable to scrap from it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect to webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\roshan.LAPTOP-IHN8RLL4\\Downloads\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "driver.get('https://www.amazon.in/')\n",
    "\n",
    "#To click on search button\n",
    "search_field = driver.find_element_by_id('twotabsearchtextbox')\n",
    "search_field.send_keys('Laptop')\n",
    "search_bt = driver.find_element_by_id('nav-search-submit-button')\n",
    "search_bt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tittle</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td></td>\n",
       "      <td>56,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HP Envy Intel 11th Gen Core i7 Processor 13.3 ...</td>\n",
       "      <td></td>\n",
       "      <td>1,24,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td></td>\n",
       "      <td>56,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>HP Pavilion (2021) Intel 11th Gen Core i7 14 i...</td>\n",
       "      <td></td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...</td>\n",
       "      <td></td>\n",
       "      <td>93,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...</td>\n",
       "      <td></td>\n",
       "      <td>1,13,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Dell 14 (2021) i7-1195G7 2in1 Touch Screen Lap...</td>\n",
       "      <td></td>\n",
       "      <td>95,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14-inc...</td>\n",
       "      <td></td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>HP Pavilion 13(2021) 11th Gen Intel Core i7 13...</td>\n",
       "      <td></td>\n",
       "      <td>89,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td></td>\n",
       "      <td>85,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tittle Ratings     Price\n",
       "0  Mi Notebook Horizon Edition 14 Intel Core i7-1...            56,990\n",
       "1  HP Envy Intel 11th Gen Core i7 Processor 13.3 ...          1,24,000\n",
       "2  Mi Notebook Horizon Edition 14 Intel Core i7-1...            56,990\n",
       "3  HP Pavilion (2021) Intel 11th Gen Core i7 14 i...            84,990\n",
       "4  Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...            93,990\n",
       "5  ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...          1,13,990\n",
       "6  Dell 14 (2021) i7-1195G7 2in1 Touch Screen Lap...            95,890\n",
       "7  HP Pavilion x360 11th Gen Intel Core i7 14-inc...            84,990\n",
       "8  HP Pavilion 13(2021) 11th Gen Intel Core i7 13...            89,700\n",
       "9  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....            85,990"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecting CPU Type filter to “Intel Core i7” and “Intel Core i9” \n",
    "search_i7=driver.find_element_by_xpath(\"//span[text()='Intel Core i7']\")\n",
    "search_i7.click()\n",
    "\n",
    "# filter for “Intel Core i9” is not availale on webpage\n",
    "\n",
    "\n",
    "\n",
    "# Now extract all the tags having the title name\n",
    "Title=[]\n",
    "t1=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "\n",
    "#Extract title text from above scraped tags with the help of for loop\n",
    "for i in t1[:10]:\n",
    "    title=i.text\n",
    "    Title.append(title)\n",
    "    \n",
    "# extract all the tags having the Ratings\n",
    "Ratings =[]\n",
    "r1 = driver.find_elements_by_xpath(\"//span[@class='a-icon-alt']\")\n",
    "\n",
    "#Extract Rating text from above scraped tags with the help of for loop\n",
    "for i in r1[:10]:\n",
    "    rating=i.text\n",
    "    Ratings.append(rating)\n",
    "\n",
    "# extract all the tags having the Price\n",
    "Price_laptop=[]\n",
    "p1 = driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "\n",
    "#Extract price text from above scraped tags with the help of for loop\n",
    "for i in p1[:10]:\n",
    "    p_laptop=i.text\n",
    "    Price_laptop.append(p_laptop)\n",
    "    \n",
    "ds=pd.DataFrame({'Tittle': Title,'Ratings':Ratings,'Price':Price_laptop})\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Top10job(link):\n",
    "    \n",
    "#lets connect to webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\roshan.LAPTOP-IHN8RLL4\\Downloads\\chromedriver_win32/chromedriver.exe\")\n",
    "\n",
    "#send get request to the webpage server to get the source code of the page\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "\n",
    "#To click on jobs button\n",
    "search_field = driver.find_element_by_xpath(\"//a[@class='link jobs']\")\n",
    "search_field.click()\n",
    "\n",
    "#     return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.Top10job(link)>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top10job('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To click on search button\n",
    "search_j = driver.find_element_by_name('ab_jobsSearch')\n",
    "search_j.send_keys('Data Scientist')\n",
    "search_btn = driver.find_element_by_xpath(\"//span[@class='ctas-btn-medium']\")\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search location \n",
    "select_loc = driver.find_element_by_xpath(\"//div[@title='Location']\")\n",
    "select_loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "enter_loc = driver.find_element_by_xpath(\"//input[@placeholder='Search locations']\")\n",
    "enter_loc.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_Noida = driver.find_element_by_xpath(\"//label[@for='location_Noida']\")\n",
    "select_Noida.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>When</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>12d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Urgent Requirement || Data Scientist || Noida</td>\n",
       "      <td>5d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Group Lead-Data Scientist</td>\n",
       "      <td>7d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Jubilant FoodWorks - Data Scientist - Deep Lea...</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Urgent Vacancy || Data Scientist || Noida</td>\n",
       "      <td>24d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Urgent Requirement || Data Scientist || Noida</td>\n",
       "      <td>24d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Manager - Data Scientist - Retail/BFSI (8-15 yrs)</td>\n",
       "      <td>1d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Data Scientist - Machine Learning (5-14 yrs)</td>\n",
       "      <td>6d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Data Scientist - Data Science/Model Developmen...</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Company      When Rating\n",
       "0                                     Data Scientist   12d ago    4.1\n",
       "1      Urgent Requirement || Data Scientist || Noida    5d ago    4.1\n",
       "2                          Group Lead-Data Scientist    7d ago    4.1\n",
       "3  Jubilant FoodWorks - Data Scientist - Deep Lea...    4d ago    3.9\n",
       "4          Urgent Vacancy || Data Scientist || Noida   24d ago    4.1\n",
       "5      Urgent Requirement || Data Scientist || Noida   24d ago    4.1\n",
       "6                              Senior Data Scientist  1mon ago    3.8\n",
       "7  Manager - Data Scientist - Retail/BFSI (8-15 yrs)    1d ago    3.9\n",
       "8       Data Scientist - Machine Learning (5-14 yrs)    6d ago    4.2\n",
       "9  Data Scientist - Data Science/Model Developmen...    4d ago    3.9"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now extract all the tags having the title company name\n",
    "Com_name=[]\n",
    "com=driver.find_elements_by_xpath(\"//a[@class='title noclick']\")\n",
    "\n",
    "#Extract company text from above scraped tags with the help of for loop\n",
    "for i in com[:10]:\n",
    "    C=i.text\n",
    "    Com_name.append(C)\n",
    "    \n",
    "# extract all the tags having the Ratings\n",
    "Rating_com =[]\n",
    "r_com = driver.find_elements_by_xpath(\"//span[@class='body-small']\")\n",
    "\n",
    "#Extract Rating text from above scraped tags with the help of for loop\n",
    "for i in r_com[:10]:\n",
    "    rati=i.text\n",
    "    Rating_com.append(rati)\n",
    "\n",
    "# extract all the tags having the days\n",
    "Days=[]\n",
    "D = driver.find_elements_by_xpath(\"//span[@class='body-small-l']\")\n",
    "\n",
    "#Extract days text from above scraped tags with the help of for loop\n",
    "for i in D[:20:2]:\n",
    "    d=i.text\n",
    "    Days.append(d)\n",
    "    \n",
    "ds=pd.DataFrame({'Company': Com_name,'When':Days,'Rating':Rating_com})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
